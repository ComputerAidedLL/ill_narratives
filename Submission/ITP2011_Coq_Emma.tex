\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}

\usepackage{url}
%\urldef{\mailsa}\path|{alfred.hofmann, ursula.barth, ingrid.haas, frank.holzwarth,|
%\urldef{\mailsb}\path|anna.kramer, leonie.kunz, christine.reiss, nicole.sator,|
%\urldef{\mailsc}\path|erika.siebert-cole, peter.strasser, lncs}@springer.com|    
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

\mainmatter  % start of an individual contribution

\title{Revisiting Interactive Narratology with Proof Assistants\\ --\\ Structural Analysis of Narratives with Proof Assistants}

% a short form should be given in case it is too long for the running head
\titlerunning{Revisiting Interactive Storytelling with Proof Assistants}
% the name(s) of the author(s) follow(s) next
%
% NB: Chinese authors should write their first names(s) in front of
% their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
%
\author{Anne-Gwenn Bosser\inst{1}%
%\thanks{Please note that the LNCS Editorial assumes that all authors have used
%the western naming convention, with given names preceding surnames. This determines
%the structure of the names in the running heads and the author index.}%
\and Pierre Courtieu\inst{2}\and Julien Forest\inst{2} \and Marc Cavazza\inst{1}}
%
%\authorrunning{Lecture Notes in Computer Science: Authors' Instructions}
% (feature abused for this document to repeat the title also on left hand pages)

% the affiliations are given next; don't give your e-mail address
% unless you accept that it will be published
\institute{University of Teesside, School of Computing, Intelligent Virtual Environments Research Group\\
\url{http://ive.scm.tees.ac.uk/}
\and
Conservatoire National des Arts et M\'{e}tiers, Laboratoire CEDRIC, Equipe CPR\\
\url{http://cedric.cnam.fr/}}

%
% NB: a more complex sample for affiliations and the mapping to the
% corresponding authors can be found in the file "llncs.dem"
% (search for the string "\mainmatter" where a contribution starts).
% "llncs.dem" accompanies the document class "llncs.cls".
%

%\toctitle{Lecture Notes in Computer Science}
%\tocauthor{Authors' Instructions}
\maketitle
\begin{abstract}
This paper proposes a novel application of Interactive Proof Assistants, for studying the formal properties of Narratives. This builds on recent work demonstrating the suitability of Intuitionistic Linear Logic (ILL) as a conceptual model for Interactive Narratives, for it provides a theory for representing the basic properties associated to narrative actions, i.e. causality and competition for resources. This extends the philosophy behind the use of LL for the representation of actions semantics in computational linguistics. Linear Logic could in the long-term support narrative generation on a principled basis, by relying on a representation of core properties rather than ad hoc narrative ontologies, such as those associated to AI approaches to narrative generation. As our approach relies on a correspondance between an ILL proof and an Interactive Narrative, a first step in that direction is to study formal properties of narratives using a direct encoding of ILL within the Coq Proof-Assistant.

More specifically, we describe a method for modelling the resources attached to narrative actions, together with constraints on the story endings and intermediate states of the narrative in the form of an ILL sequent. From this specification, we describe how different interactive narratives can be obtained (by cut-free proof trees of the sequent) and verified with Coq, thus allowing to assist the generation of well-formed interactive stories. We finally describe how Coq allows to reason about interactive narratives at the structural level: to formally prove second order properties, such as properties traversing all the interactive narratives a given sequent specification can generate.
\keywords{Linear Logic, Applications of Theorem Provers, Interactive Narratives}
\end{abstract}


\section{Introduction}
Proofs as narratives.

Proposed method:
- a formalisation, "by hand" of interactive narratives specifications in the form of an ILL sequent.
- a method for unfolding a given narrative specified by such a sequent using Coq, thus allowing to assist the generation of well-formed stories.
- methods for proving structural properties on the stories a sequent can generate.

Further work: tactics based on patterns of use.
\section{Related Works}
\subsection{Logical Approaches to Interactive Storytelling}
inclure travaux avec LL.\\
meme approche que pour papier ECAI mais en insistant plus sur usages de LL + model checking via petri nets/colored petri nets.\\
LL tool support for IS: model checking w. petri nets. Montrer la difference de l'approche auto/prouveur avec une approche Proof Assistant. Insister sur le fait que meme si ils semblent inclure tous les connecteurs on voit pas bien comment ils s'en sortent pour l'indecidabilite, et que le fragment de LL utilise est vraiment pas clair du tout.
\subsection{Related applications of Linear Logic}
computational linguistics: a ete utilise pour la representation d'actions. Ici on etend a un context d'action narratives.\\
LL and planning: idem, representation d'actions.\\
Referer a ECAI-LL-Emma comme "evidence" que LL presente une theorie de l'action particulierement adaptee a la narration interactive.
\subsection{Proof Assistants and Automatic Provers support for LL}
Encodings existants (plusieurs naifs, certains sans proof-terms (juste oui/non) ce qui ne convient pas, c'est la preuve qui nous interesse pas le fait que ce soit prouvable seulement. 

Les proches:Dixon, LLP, Prover de Ronan?: 
Dixon: usage "proche" car pour de la planif + le seul exemple d'encodage d'ILL avec des tactiques un peu elaborees dans un assistant de preuve. Nous, on a pas de tactiques definies, mais cet exemple montre que c'est possible et qu'il y a tout un champ qui a ete tres peu investigue par la recherche, et qui a un gros potentiel d'automatisation/semi-automatisation. Les approches Prouveur automatique  a la LLProver (qui mouline 3 semaines sans que rien ne sorte...) et Petri nets ne permettent pas en l'etat actuel des connaissances de passer au niveau du fragment ILL qui est suffisament expressif. L'approche Assistant de Preuve semi-automatique est une premiere etape, permettant d'etudier dans le futur des tactiques performantes, sans avoir a restreindre l'expressivite du fragment considere. Ces consideration sont pour des travaux futurs sur une automatisation ou automatisation partielle.

Pour notre sujet, l'analyse de proprietes de narration interactives, et de specification de narration interactives, avantage qu'il y a a pouvoir faire des preuves au second ordre grace a une approche proof-assistant, comparee a une approche prouveur automatique: Meme sans automatisation, un assistant de preuve permet d'exprimer des proprietes "arbitraires" au second ordre sur une specification de narrations interactives: de raisonner sur un ensemble d'histoires que peut generer la specification. Ceci permet ensuite de verifier ces proprietes (qui sont structurelles, et suivant notre analogie, mappee sur la structure de la preuve), ou d'exhiber une narration interactive particuliere verifiant une propriete structurelle donnee. C'est ce qu'on discute dans ce papier.
\section{ILL as a Representational Theory for IS}
%Referer a ECAI, mais decrire plus precisement que pour ECAI ou c'etait pour le moins fumeux. Faire passer l'idee que c'est une methode. A partir d'une description faite par un auteur de narration interactive, il est "simple" (sisi) d'extraire la formalisation sous forme d'un sequent. Rectifier mecomprehension de l'article de Spierling ici: on ne pretend (surtout) pas faire de l'authoring, on ne pretend pas non plus qu'on puisse extraire directement une narration interactive d'une histoire lineaire. On dit juste que de la specification de conditions initiales, ressources, et actions narratives, on peut faire une analyse formelle d'un ensemble de narrations interactives, du point de vue de leurs proprietes structurelles, grace a une correspondance preuve-narration interactive. 
%other description in~\cite{Bosser10}.
%
Our approach is based on a formal specification of interactive narratives resources (including narrative actions), initial conditions, and possible ending states in the form of an ILL sequent. We then interpret a given proof of such a sequent as an interactive narrative. A sequent may have multiple proofs. It may therefore specify multiple interactive narratives sharing the same characteristics. When interpreting the proof as an interactive narrative, we look for a trace of the use of the $\multimap$ left rule and $\oplus$ left rule. The first is interpreted as the execution of a narrative action and the second one as an external branching choice of the narrative in an open-world assumption (for instance, end-user interaction).  
\subsection{Modelisation of Interactive narrative specifications through an ILL sequent}
% description de la modelisation du sequent
The choice of linear logic for representing interactive narratives was originally motivated by the need to capture the nature of narrative actions, and in particular their causal properties. Indeed, the description of narrative causality requires being able to express the semantic of narrative actions, which is modelled very precisely thanks to the explicit management of resources allowed by Linear Logic~\cite{Bosser10}. Using Linear Logic for Knowledge Representation for action semantics also allows to elegantly avoid the frame problem presented by other AI formalism such as the situation calculus. 

The specification of a narrative thus encompasses the description of the available resources and states of the narratives, the description of the semantic of narrative actions through their impact on the context of execution, and the possible ending states of the narrative. It takes the form of a sequent $\Gamma , \Delta \vdash \phi$, where $\Gamma$ is a multiset representing resources and initial conditions, $\Delta$ is a multiset representing the possible narrative actions, and $\phi$ a formula representing the possible ending state of the narrative. A sequent thus provides the knowledge representation base of a set of interactive narratives. 

While the description of the whole sequent places us in the whole ILL fragment, the modelisation method we propose for this paper causes restrictions on the structure of formulae in each of the multisets and on the right-hand side formula. This will in turn cause certain restrictions on the properties of the generated proofs which we can verify, and will subsequently allow us to explore ad-hoc tactics.
\subsubsection{Resources of an Interactive Narrative}
Part of the left-hand side of the sequent consists in the description of the available resources and initial states. The subset language for these formulas is described on figure~\ref{sequent_grammars}. A resource can be an atom, 1, or composed. The formula $R_{1}\&R_{2}$, expresses the availability of one of the resources. One only of $R_{i}$ will be used and the choice depends on the proof, or on the branches of the proof. This allows us to describe how the initial conditions can adapt to a given unfolding of the story. The formula $R_{1} \otimes R_{2}$ allows to express the availability of both resources. The formula $!R$ allows to express the unbounded availability of the resource $R$.
\begin{figure}
Resources in $\Gamma$: $R::= 1| atom | R_{1}\&R_{2} | R_{1} \otimes R_{2} | !R $\\
Action consumption: $Ac ::= 1 | atom | Ac_{1}\&Ac_{2} | Ac_{1} \otimes Ac_{2}$\\
Action product: $Ap::= R | A | Ap_{1} \otimes Ap_{2} | Ap_{1}\& Ap_{2} | !Ap$\\
Actions in $\Delta$: $A::= 1 | Ac \multimap Ap | A_{1} \oplus A_{2} | A\& A$

Ending state $\phi$: $E::= atom | E_{1} \otimes E_{2} | E_{1} \oplus E_{2}$
\caption{Grammars for the sequent $\Gamma , \Delta \vdash \phi$ specifying a narrative\label{sequent_grammars}}
\end{figure}
\subsubsection{Narrative Actions Representation}
A simple narrative action is of the form $R \multimap Ap$, where $R$ is a resource and $Ap$ the product of an action. Its semantic is thus precisely defined in terms of how it affects the execution environment (the rest of the sequent context): the execution of the narrative action corresponds to the application of the $\multimap$ left rule in the proof. While actions can only consume resources formulae, they can augment the execution environment with formulae corresponding to both resources and actions. Figure~\ref{sequent_grammars} describes the subset of linear logic formulae corresponding to actions.

Actions can be composed for offering two types of choices. A composed action $A_{1} \oplus A_{2}$ corresponds to an external choice in an open-world assumption. This is used, for instance, for modeling end-user interaction with the interactive narrative. When such an action is decomposed using the $\oplus$ rule, two sub-proofs are created, and interpreted as the two possible unfolding of the story. A composed action $A_{1} \& A_{2}$ corresponds to an internal choice, depending on the proof-search. If both choices successfully produce a different proof of the sequent, this will possibly generate two different interactive narratives.
\subsubsection{Possible ending states}
The resulting state of a narrative can be expressed in the subset of ILL composed of $\otimes$ and $\oplus$, respectively for the availability of both resulting states or a choice between states. 
%Analyser les proprietes structurelles d'une preuve = Analyser les proprietes intrinseques d'une histoire interactive.
\subsubsection{Interpreting a proof as an Interactive narrative}
Interactive narratives can be extracted from proofs from a trace of the order of execution of linear implication. The resulting tree branches with the application of 
\subsubsection{Soundness of the representation}
Lemme de Pierre: langage de representation du sequent est stable sur la preuve en Coq: on a jamais d'implication en sous-formule gauche d'une application.
Preuve en Coq que: on peut toujours se ramener a une preuve ou toutes les implications left seront sur une branche a droite (par rapport aux branches de l'implication left)?


\textbf{Cas d'utilisation 1: construction du sequent qui servira de fil d'Ariane dans la suite, pour illustrer la methode}
\section{Using the Coq proof assistant for Story Properties Analysis}
\subsection{ILL encoding into Coq}
quelques details techniques. Comparer avec encodings existants si necessaire (y'en a peu, mais certains pour Isabelle sont plus aboutis avec tactiques). Le truc est simple, expliquer pourquoi.
%\subsection{Specifying Interactive Narratives}
%methode/cuisine pour ecrire le sequent. Faut que ca paraisse facile, et suive naturellement la description de la theorie representationnelle.
\subsection{Unfolding a Story}
Generation "assistee" d'histoires interactives \emph{well-formed}. Bien dire que si pour l'instant on ne fait que de la verif, il est possible de definir des tactiques efficaces (e.g full auto), meme pour ILL. Ca na pas ete tres recherche mais Dixon a certains resultats preliminaires. Un objectif futur est de travailler sur des tactiques, y compris ad-hoc et correspondant a des usage patterns (voir ce qui a ete fait en computational linguistics avec succes), et qu'il n'est pas completement sans espoir de penser a une tactique "trivial" future (full-automation) meme si c'est un vrai probleme car ILL est indecidable. Des arguments places ici doivent etre retires de l'etat de l'art et vice-versa, voir ce qui rend le mieux.

Preuve en tant qu'objet de l'etude et non pas prouvabilite.

\textbf{Cas d'utilisation 2: une preuve du sequent qui suit l'ordre du roman, preuve assistee meme si pas full-auto}

Exemple de la preuve deroulee, de maniere assistee: une instance d'un sequent assez generatif. On montre comment on a produit la preuve en Coq, et on raconte l'histoire correspondante, avec les choix possibles de l'utilisateur. 

Il faut que ca fasse "methode". Ideal, un truc du genre: l'utilisateur choisit une action narrative a executer, et une tactique Coq deroule la suite, jusqu'a ce qu'il y aie une nouvelle formule a decomposer. Le contexte est coupe en 2 en fait: il y a les formules qui correspondent a des actions narratives ou composition d'actions narratives, et des trucs qui sont "juste" des ressources ou des etats consommes par les actions. L'utilisateur ne travaille que sur les premieres et Coq l'aide pour les "details".

Considerations sur les possibles alternatives par rapport a la structure de la specification, pour lier avec la suite: les "choix internes" a la recherche de preuve, l'ordre d'execution des actions. Montrer qu'on ne peut pas construire d'histoires qui sont mal formees du point de vue des ressources disponibles (e.g. dans notre cas, commencer par aller voir Rodolphe et choisir de s'enfuir).
\section{Perspectives}
\subsection{2nd order analysis of interactive narratives specification}
(Decrire le passage assiste par Coq au second ordre: C'est ce qu'on a en plus par rapport a un prouveur)
\\
Inspection des proprietes d'une preuve/histoire -> Inspection des proprietes de l'ensemble des histoires specifiees par un sequent.\\
Inspection n'est pas basee forcement sur des proprietes generiques, on inspecte ce qu'on veut!

\textbf{Cas d'utilisation 3: prouver des proprietes structurelles au second ordre, e.g. sur toutes les histoires que genere le sequent. La les tactiques de base ne marcheront pas. Preuve a la main, mais qui est verifiee par le systeme}
Exemple des 2 proprietes-meta, de type "toute histoire generee par cette specification de ressources, conditions initiales, et actions narratives, verifie telle propriete":\\
- preuves sur l'accessibilite des fins possibles. Ronan fait ca aussi avec ses reseaux de petri? Mais dans un cadre plus facile, MML jusqu'a preuve du contraire\\
- preuve qu'une action donnee se produira toujours avant une autre, meme sans rapports de precedence/causalite directement encode dans le sequent. Dans l'exemple, a cause d'une configuration particuliere de competition pour la consommation de ressources narratives provoquee par une "interaction" possible. \textbf{Cela met dans cet exemple en evidence une relation structurelle de la specification, qui emerge de l'analyse, et qui est a priori non evidente: elle n'est pas encodee directement dans les specifications.}
\textbf{Cas d'utilisation 4: exhiber une instance particuliere de narration interactive, qui verifie une propriete structurelle donnee}
Avec l'exemple: exhiber une histoire interactive ayant plusieurs fins possibles suivant le "chemin" parcouru par l'utilisateur.
ajout, au second ordre, de contraintes sur la recherche de preuve. Permet de resoudre des problemes non traites?
Lorsque tactiques pour automatiser seront definies, cela permettra de rechercher/generer des histoires verifiant certaines proprietes structurelles: presence de fins alternatives etc.
\section{Conclusion}
On a montre que: un couplage ILL et Proof assistant fourni un outil puissant pour etudier les proprietes structurelles de narrations interactives.//
On a fourni: une methode d'encodage IS en sequent ILL, une methode pour derouler une narration interactive correspondante en utilisant Coq.//
Insister:\\
A partir d'un encodage/specification des conditions initiales, actions narratives, et open-world input, a faire a la main selon une methode que nous avons definie ici -> une methode reposant sur des tactiques de Coq pour derouler une histoire.
\end{document}
